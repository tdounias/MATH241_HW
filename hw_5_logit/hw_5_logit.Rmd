---
title: "hw_5_logit"
author: "Theodore Dounias"
date: "March 29, 2017"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyr)
library(dplyr)
library(lubridate)
library(ISLR)
library(ggplot2)

```

##Tidying the Data:
  
After reading everything in, I took a sample. I proceeded to tidy the data into the workable form we use, and then wrote that into a csv. In this exercise I will prefer to read from that CSV instead of doint the tidy steo again in rmd. 
I attach the code with eval = FALSE.
  
```{r, eval = FALSE}
#Read File
voter_large <- read.csv(".....")

#Take sample
set.seed(251981)
voter_sample <- sample_n(voter_large, 100000, replace = FALSE)
write.csv(voter_sample, file = "voter_sample.csv")

#Tidy your RAM!
rm(voter_large)

#Lubridate
voter$BIRTH_DATE.x <- mdy(voter$BIRTH_DATE.x)

#Select off useful variables and create AGE variable
voter <- voter %>%
  select(2, 6:7, 16) %>%
  filter(X11.08.2016 == "NO"| X11.08.2016 == "YES" ) %>%
  mutate(AGE = 2016 - year(BIRTH_DATE.x)) %>%
  select(-1)

#Create VOTED variable
voter$X11.08.2016 <- ifelse(voter$X11.08.2016 == "YES", 1, 0)

colnames(voter) <- c("PARTY_CODE", "COUNTY", "VOTED", "AGE")

#Create usefull PARTY variable  
voter$PARTY_CODE <- ifelse(voter$PARTY_CODE == "DEM", "DEMOCRAT", 
                           ifelse(voter$PARTY_CODE == "REP", "REPUBLICAN", "OTHER"))

#Write to folder
write.csv(voter, file = "voter_logit.csv")
```
  
##Fitting and Assesing Models
  
I will provide all the code here, and in the next section include any written assesment:
```{r}

#Read File
voter <- read.csv("C:\\Users\\tdounias\\Desktop\\Reed College\\Spring 2017\\MATH 241\\Repositories\\theodore_dounias\\hw_5_logit\\data\\voter_logit.csv")

#Split the sample
set.seed(251981)
voter_indices <- sample(1:nrow(voter), size = nrow(voter)/2, replace = FALSE)
voter_train <- slice(voter, voter_indices)
voter_test  <- slice(voter, -voter_indices)

#Fit the models
m_age <- glm(VOTED ~ AGE, data = voter_train, family = binomial)

m_party <- glm(VOTED ~ AGE + PARTY_CODE, data = voter_train, family = binomial)

m_county <- glm(VOTED ~ AGE + PARTY_CODE + COUNTY, data = voter_train, family = binomial)

AGE2 <- voter_train$AGE^2

m_age2 <- glm(VOTED ~ AGE + I(AGE^2), data = voter_train, family = binomial)

#Make predictions for voter_test
y1 <- predict(m_age, newdata = voter_test, type = "response")
y2 <- predict(m_party, newdata = voter_test, type = "response")
y3 <- predict(m_county, newdata = voter_test, type = "response")
y4 <- predict(m_age2, newdata = voter_test, type = "response")
mcr <- c(0, 0, 0, 0)

#Generate mcr's
voter_test1 <- voter_test %>%
  mutate(p_hat        = y1,
         pred_vote = p_hat > .5)

confusion_mat1 <- voter_test1 %>%
  group_by(VOTED, pred_vote) %>%
  tally()

mcr[1] <- confusion_mat1[1,3]/nrow(voter_test)

voter_test2 <- voter_test %>%
  mutate(p_hat        = y2,
         pred_vote = p_hat > .5)

confusion_mat2 <- voter_test2 %>%
  group_by(VOTED, pred_vote) %>%
  tally()

mcr[2] <- (confusion_mat2[2,3] + confusion_mat2[3,3])/nrow(voter_test)

voter_test3 <- voter_test %>%
  mutate(p_hat        = y3,
         pred_vote = p_hat > .5)

confusion_mat3 <- voter_test3 %>%
  group_by(VOTED, pred_vote) %>%
  tally()

mcr[3] <- (confusion_mat3[2,3] + confusion_mat3[3,3])/nrow(voter_test)

voter_test4 <- voter_test %>%
  mutate(p_hat        = y4,
         pred_vote = p_hat > .5)

confusion_mat4 <- voter_test4 %>%
  group_by(VOTED, pred_vote) %>%
  tally()

mcr[4] <- (confusion_mat4[2,3] + confusion_mat4[3,3])/nrow(voter_test)

#Print!
mcr


```

##Written Assesment of Results:
  
**Coefficients**
  
To judge the models we need to examine them:
```{r}
summary(m_age)
summary(m_party)
summary(m_county)
summary(m_age2)
```
  
Based on this examination, we get the following results:
  
* The simple age model shows an increase of the probability to vote by 3.9%
  
* The age model checked for party shows an increase of 3.2%
   
* The age model checked for county shows an increase of 3.3%
   
* The final age model shows an increase of close to 9.8%, which diminishes at higher ages.
  
**Misclassification**
  
The first three models show the same misclassification rate, which is about the same as if our model was that everyone voted (close to .19). The final model, interestingly and probably incorrectly, shows a misclassification rate of .28, meaning that it is actually a _worse_ model than the first. This should probably not happen, given that adding a quadratic part should normaly restrict the bias in the model.

**Summary**
  
  There are two points of interest in analyzing probability to vote. First, whether we can see a trend; if, for some reason, one group or another votes more consistently, so we can later examine why this happens. Second, so that we can build a system of predicting whether or not an individual will vote, based on the information we have about them. 
  On the first question, when examining age and party in relation to voting in Oregon, there are two clear trends. First, the probability of an individual voting increases steadily with age; in all our models the older the voter, the more likely to participate in the electoral process. Second, "mainstream" party supporters are also more likely to turn out to vote than non-affiliated or third party voters. This makes intuitive sense as well; less marginalized political groups tend to be more likely, by definition, to participate in an election.
  On the first question, our data shows that neither age nor party can help us build a model to predict turnout. More specifically, a model is a good predictor when it can, with less fault than if we just assume that everyone voted, give a good estimate of the umber of people that will vote. Our models with age and party do not fulfill this criterium, and therefore cannot be considered worthwhile.

